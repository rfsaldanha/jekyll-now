A revista Wired publicou no dia 19/set um ![artigo](https://www.wired.com/story/ai-research-is-in-desperate-need-of-an-ethical-watchdog/) interessante sobre privacidade e inteligência artificial, debatendo sobre o caso de um ![algoritmo](https://osf.io/zn79k/) que consegue distinguir orientações sexuais através de fotografias.

A grande pergunta é: precisamos de um comitê de ética para regular usos de inteligência artificial? Na ciência tradicional, os comitês de ética das universidades e institutos regulam a pesquisa acadêmica, avaliando se um projeto pode seguir em frente seguindo certos parâmetros éticos.

Assim, para fazer algumas perguntas (instrumento/questionário) para algumas pessoas (amostra), o comitê de ética avalia se a privacidade esta sendo indevidamente invadida ou se há possibilidade dos entrevistados se prejudicarem de alguma forma pela condução da pesquisa.

Com as técnicas de inteligência artificial, como machine learning, torna-se praticamente possível responder as mesmas questões sem fazer as perguntas. E sem a pessoa souber.

No caso do algoritmo citado, seria como pular a pergunta "Qual é a sua orientação sexual?", obtendo esta resposta através de alguma fotografia pública no Facebook.

Tendo acesso aos bancos de dados corretos, pode-se prever diversas respostas a perguntas que talvez não fossem autorizadas por um comitê de ética em uma pesquisa tradicional.

Atualmente, a relação de comitês de ética com pesquisas com dados secundários é diversificada. Algumas instituições dispensam a apreciação da pesquisa pelo comitê, enquanto outras pedem/exigem que o projeto seja submetido para apreciação, independente da origem dos dados (primários ou secundários).

Esta situação tem se sustentado pois até pouco tempo não era possível descobrir tantos detalhes sobre indivíduos através de bancos de dados públicos, mas a IA está mudando este cenário como um olho que reflete a realidade.

![The false mirror](https://www.renemagritte.org/images/paintings/the-false-mirror.jpg)
